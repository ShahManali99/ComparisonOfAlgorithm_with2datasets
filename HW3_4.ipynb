{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title This code implements the training of the decision tree.\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score # Use accruacy_score to find out accuracy of your model\n",
        "\n",
        "def dt_training(dataset, testing_dataset, depth):\n",
        "    # Extracting the features and labels from dataset\n",
        "    x_train = [data[:2] for data in dataset]\n",
        "    y_train = [data[2] for data in dataset]\n",
        "\n",
        "    x_test = [data[:2] for data in testing_dataset]\n",
        "    y_test = [data[2] for data in testing_dataset]\n",
        "\n",
        "    # To-Do\n",
        "    # Use sklearn's Decision Tree Classifier (with max_depth = depth)\n",
        "    model = tree.DecisionTreeClassifier(max_depth=depth)\n",
        "    # Train the model using the x_train and y_train\n",
        "    model = model.fit(x_train,y_train)\n",
        "    # Run prediction after training on the testing dataset\n",
        "    y_pred = model.predict(x_test)\n",
        "    # Calculating accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-UlrBlk5_OuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title This code implements the training of the random forest.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score # Use accruacy_score to find out accuracy of your model\n",
        "\n",
        "def rf_training(dataset, testing_dataset):\n",
        "    # Extracting the features and labels from dataset\n",
        "    x_train = [data[:2] for data in dataset]\n",
        "    y_train = [data[2] for data in dataset]\n",
        "\n",
        "    x_test = [data[:2] for data in testing_dataset]\n",
        "    y_test = [data[2] for data in testing_dataset]\n",
        "\n",
        "    # To-Do\n",
        "    # Use sklearn's random forest Classifier (with 30 trees in the forest and max_depth = 3)\n",
        "    rf = RandomForestClassifier(n_estimators = 30, max_depth = 3)\n",
        "    # Train the model using the x_train and y_train\n",
        "    rf.fit(x_train, y_train)\n",
        "    # Run prediction after training on the testing dataset\n",
        "    y_pred = rf.predict(x_test)\n",
        "    # Calculating accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "CphNY-wiHnpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title This code implements the training of the support vector machine (SVM).\n",
        "\n",
        "from sklearn.svm import SVC # This package will help you run the direct SVM model\n",
        "from sklearn.metrics import accuracy_score # Use accruacy_score to find out accuracy of your model\n",
        "\n",
        "def svm_training(dataset, testing_dataset):\n",
        "    # Extracting the features and labels from dataset\n",
        "    x_train = [data[:2] for data in dataset]\n",
        "    y_train = [data[2] for data in dataset]\n",
        "\n",
        "    x_test = [data[:2] for data in testing_dataset]\n",
        "    y_test = [data[2] for data in testing_dataset]\n",
        "\n",
        "    # Training using SVC with a linear kernel\n",
        "    clf = SVC(kernel='linear', C=1)  # LBF SVM with C=1\n",
        "    clf.fit(x_train, y_train) # Train the model using the x_train and y_train\n",
        "\n",
        "    # Predicting on test dataset\n",
        "    y_pred = clf.predict(x_test)\n",
        "\n",
        "    # Calculating accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    #print(\"Accuracy:\", accuracy)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "J-Iz8OxxwCeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(set):\n",
        "\n",
        "    # Initilize the dataset\n",
        "    Sn = [] # List to store negative samples\n",
        "    Sp = [] # List to store positive samples\n",
        "    num_n = 0 # Counter for negative samples\n",
        "    num_p = 0 # Counter for positive samples\n",
        "    target_num_samples = 100\n",
        "\n",
        "    if set==1:\n",
        "      while len(Sp) < target_num_samples*2 or len(Sn) < target_num_samples*2:\n",
        "        i1, i2 = np.random.uniform(-5, 5, 2)\n",
        "        if i1 + i2 >= 0 and len(Sp) < target_num_samples*2:\n",
        "            Sp.append([i1, i2, 1])\n",
        "        elif i1 + i2 < 0 and len(Sn) < target_num_samples*2:\n",
        "            Sn.append([i1, i2, -1])\n",
        "    else:\n",
        "      while num_p < target_num_samples*2 or num_n < target_num_samples*2:\n",
        "          i1 = np.random.uniform(-10, 10)\n",
        "          i2 = np.random.uniform(-10, 10)\n",
        "          if i1>-5 and i1<5 and i2>-5 and i2<5:\n",
        "              if num_p < target_num_samples*2:\n",
        "                  Sp.append([i1] + [i2] + [1])\n",
        "                  num_p +=1\n",
        "          elif num_n < target_num_samples*2:\n",
        "              Sn.append([i1] + [i2] + [-1])\n",
        "              num_n +=1\n",
        "\n",
        "    # Splitting samples into training and testing samples\n",
        "    testing_samples = Sp[target_num_samples:] + Sn[target_num_samples:]\n",
        "\n",
        "    # First split: subset of the samples used for training\n",
        "    training_samples = Sp[:target_num_samples] + Sn[:target_num_samples]\n",
        "\n",
        "    return training_samples, testing_samples"
      ],
      "metadata": {
        "id": "gqhA9B-Ht9Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsBMaYMoJqj",
        "outputId": "b14a3dc2-e52c-4439-837d-9250b0b53181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy (and standard deviation) using SVM for dataset 1: 0.9864999999999999 0.012325447929656225\n",
            "Average Accuracy (and standard deviation) using DT3 for dataset 1: 0.8945000000000002 0.03160564295607142\n",
            "Average Accuracy (and standard deviation) using DT4 for dataset 1: 0.923 0.026913441499245926\n",
            "Average Accuracy (and standard deviation) using RF  for dataset 1: 0.9346666666666666 0.024390344173235597\n",
            "Average Accuracy (and standard deviation) using SVM for dataset 2: 0.5844999999999999 0.031127426277587845\n",
            "Average Accuracy (and standard deviation) using DT3 for dataset 2: 0.9130000000000001 0.0178232058470598\n",
            "Average Accuracy (and standard deviation) using DT4 for dataset 2: 0.9903333333333334 0.008459051693633021\n",
            "Average Accuracy (and standard deviation) using RF  for dataset 2: 0.9881666666666666 0.009263128821060177\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "avg_acc_1_svm = []\n",
        "avg_acc_1_dt3 = []\n",
        "avg_acc_1_dt4 = []\n",
        "avg_acc_1_rf = []\n",
        "avg_acc_2_svm = []\n",
        "avg_acc_2_dt3 = []\n",
        "avg_acc_2_dt4 = []\n",
        "avg_acc_2_rf = []\n",
        "\n",
        "for r in range(30):\n",
        "\n",
        "  # Create first dataset\n",
        "  training_data, testing_data = generate_samples(1)\n",
        "\n",
        "  # Train the SVM LBF using the training sample set 1\n",
        "  accuracy = svm_training(training_data, testing_data)\n",
        "  avg_acc_1_svm.append(accuracy)\n",
        "\n",
        "  # Train the DT using the training sample set 1, and max_depth = 3\n",
        "  accuracy = dt_training(training_data, testing_data,3)\n",
        "  avg_acc_1_dt3.append(accuracy)\n",
        "\n",
        "  # Train the DT using the training sample set 1, and max_depth = 4\n",
        "  accuracy = dt_training(training_data, testing_data,4)\n",
        "  avg_acc_1_dt4.append(accuracy)\n",
        "\n",
        "  # Train the RF using the training sample set 1\n",
        "  accuracy = rf_training(training_data, testing_data)\n",
        "  avg_acc_1_rf.append(accuracy)\n",
        "\n",
        "  # Create second dataset\n",
        "  training_data, testing_data = generate_samples(2)\n",
        "\n",
        "  # Train the SVM LBF using the training sample set 2\n",
        "  accuracy = svm_training(training_data, testing_data)\n",
        "  avg_acc_2_svm.append(accuracy)\n",
        "\n",
        "  # Train the DT using the training sample set 1, and max_depth = 3\n",
        "  accuracy = dt_training(training_data, testing_data,3)\n",
        "  avg_acc_2_dt3.append(accuracy)\n",
        "\n",
        "  # Train the DT using the training sample set 1, and max_depth = 4\n",
        "  accuracy = dt_training(training_data, testing_data,4)\n",
        "  avg_acc_2_dt4.append(accuracy)\n",
        "\n",
        "  # Train the RF using the training sample set 2\n",
        "  accuracy = rf_training(training_data, testing_data)\n",
        "  avg_acc_2_rf.append(accuracy)\n",
        "\n",
        "print(\"Average Accuracy (and standard deviation) using SVM for dataset 1:\", np.mean(avg_acc_1_svm), np.std(avg_acc_1_svm))\n",
        "print(\"Average Accuracy (and standard deviation) using DT3 for dataset 1:\", np.mean(avg_acc_1_dt3), np.std(avg_acc_1_dt3))\n",
        "print(\"Average Accuracy (and standard deviation) using DT4 for dataset 1:\", np.mean(avg_acc_1_dt4), np.std(avg_acc_1_dt4))\n",
        "print(\"Average Accuracy (and standard deviation) using RF  for dataset 1:\", np.mean(avg_acc_1_rf), np.std(avg_acc_1_rf))\n",
        "print(\"Average Accuracy (and standard deviation) using SVM for dataset 2:\", np.mean(avg_acc_2_svm), np.std(avg_acc_2_svm))\n",
        "print(\"Average Accuracy (and standard deviation) using DT3 for dataset 2:\", np.mean(avg_acc_2_dt3), np.std(avg_acc_2_dt3))\n",
        "print(\"Average Accuracy (and standard deviation) using DT4 for dataset 2:\", np.mean(avg_acc_2_dt4), np.std(avg_acc_2_dt4))\n",
        "print(\"Average Accuracy (and standard deviation) using RF  for dataset 2:\", np.mean(avg_acc_2_rf), np.std(avg_acc_2_rf))\n"
      ]
    }
  ]
}